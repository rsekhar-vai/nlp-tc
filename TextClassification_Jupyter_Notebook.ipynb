{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TextClassification - Jupyter Notebook",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMwR2cficuOWKC1SvsOd7zl",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rsekhar-vai/nlptc/blob/master/TextClassification_Jupyter_Notebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iK41J9S1tbFM",
        "colab_type": "text"
      },
      "source": [
        "## Setup the Environment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DhK0DzDxpYMR",
        "colab_type": "code",
        "outputId": "55028523-1509-466c-9c3f-f0f0e698762e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "!rm -r nlptc\n",
        "!git clone https://github.com/rsekhar-vai/nlptc.git"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'nlptc'...\n",
            "remote: Enumerating objects: 65, done.\u001b[K\n",
            "remote: Counting objects:   1% (1/65)\u001b[K\rremote: Counting objects:   3% (2/65)\u001b[K\rremote: Counting objects:   4% (3/65)\u001b[K\rremote: Counting objects:   6% (4/65)\u001b[K\rremote: Counting objects:   7% (5/65)\u001b[K\rremote: Counting objects:   9% (6/65)\u001b[K\rremote: Counting objects:  10% (7/65)\u001b[K\rremote: Counting objects:  12% (8/65)\u001b[K\rremote: Counting objects:  13% (9/65)\u001b[K\rremote: Counting objects:  15% (10/65)\u001b[K\rremote: Counting objects:  16% (11/65)\u001b[K\rremote: Counting objects:  18% (12/65)\u001b[K\rremote: Counting objects:  20% (13/65)\u001b[K\rremote: Counting objects:  21% (14/65)\u001b[K\rremote: Counting objects:  23% (15/65)\u001b[K\rremote: Counting objects:  24% (16/65)\u001b[K\rremote: Counting objects:  26% (17/65)\u001b[K\rremote: Counting objects:  27% (18/65)\u001b[K\rremote: Counting objects:  29% (19/65)\u001b[K\rremote: Counting objects:  30% (20/65)\u001b[K\rremote: Counting objects:  32% (21/65)\u001b[K\rremote: Counting objects:  33% (22/65)\u001b[K\rremote: Counting objects:  35% (23/65)\u001b[K\rremote: Counting objects:  36% (24/65)\u001b[K\rremote: Counting objects:  38% (25/65)\u001b[K\rremote: Counting objects:  40% (26/65)\u001b[K\rremote: Counting objects:  41% (27/65)\u001b[K\rremote: Counting objects:  43% (28/65)\u001b[K\rremote: Counting objects:  44% (29/65)\u001b[K\rremote: Counting objects:  46% (30/65)\u001b[K\rremote: Counting objects:  47% (31/65)\u001b[K\rremote: Counting objects:  49% (32/65)\u001b[K\rremote: Counting objects:  50% (33/65)\u001b[K\rremote: Counting objects:  52% (34/65)\u001b[K\rremote: Counting objects:  53% (35/65)\u001b[K\rremote: Counting objects:  55% (36/65)\u001b[K\rremote: Counting objects:  56% (37/65)\u001b[K\rremote: Counting objects:  58% (38/65)\u001b[K\rremote: Counting objects:  60% (39/65)\u001b[K\rremote: Counting objects:  61% (40/65)\u001b[K\rremote: Counting objects:  63% (41/65)\u001b[K\rremote: Counting objects:  64% (42/65)\u001b[K\rremote: Counting objects:  66% (43/65)\u001b[K\rremote: Counting objects:  67% (44/65)\u001b[K\rremote: Counting objects:  69% (45/65)\u001b[K\rremote: Counting objects:  70% (46/65)\u001b[K\rremote: Counting objects:  72% (47/65)\u001b[K\rremote: Counting objects:  73% (48/65)\u001b[K\rremote: Counting objects:  75% (49/65)\u001b[K\rremote: Counting objects:  76% (50/65)\u001b[K\rremote: Counting objects:  78% (51/65)\u001b[K\rremote: Counting objects:  80% (52/65)\u001b[K\rremote: Counting objects:  81% (53/65)\u001b[K\rremote: Counting objects:  83% (54/65)\u001b[K\rremote: Counting objects:  84% (55/65)\u001b[K\rremote: Counting objects:  86% (56/65)\u001b[K\rremote: Counting objects:  87% (57/65)\u001b[K\rremote: Counting objects:  89% (58/65)\u001b[K\rremote: Counting objects:  90% (59/65)\u001b[K\rremote: Counting objects:  92% (60/65)\u001b[K\rremote: Counting objects:  93% (61/65)\u001b[K\rremote: Counting objects:  95% (62/65)\u001b[K\rremote: Counting objects:  96% (63/65)\u001b[K\rremote: Counting objects:  98% (64/65)\u001b[K\rremote: Counting objects: 100% (65/65)\u001b[K\rremote: Counting objects: 100% (65/65), done.\u001b[K\n",
            "remote: Compressing objects: 100% (54/54), done.\u001b[K\n",
            "remote: Total 65 (delta 28), reused 18 (delta 5), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (65/65), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eknF2zAupmQQ",
        "colab_type": "code",
        "outputId": "8b0fbc09-479c-4328-93f1-cea6a19fbfb9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "from argparse import Namespace\n",
        "from collections import Counter\n",
        "import json\n",
        "import os\n",
        "import re\n",
        "import string\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from tqdm import tqdm_notebook\n",
        "from sklearn import preprocessing\n",
        "from sklearn.model_selection import train_test_split\n",
        "import sys\n",
        "import spacy\n",
        "import torchtext\n",
        "from torchtext import data\n",
        "from torchtext.data import Field, BucketIterator\n",
        "from torchtext import vocab\n",
        "\n",
        "\n",
        "print('Python version:',sys.version)\n",
        "print('Pandas version:',pd.__version__)\n",
        "print('Pytorch version:', torch.__version__)\n",
        "print('Torch Text version:', torchtext.__version__)\n",
        "print('Spacy version:', spacy.__version__)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Python version: 3.6.9 (default, Nov  7 2019, 10:44:02) \n",
            "[GCC 8.3.0]\n",
            "Pandas version: 1.0.3\n",
            "Pytorch version: 1.4.0\n",
            "Torch Text version: 0.3.1\n",
            "Spacy version: 2.2.4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "inC1xAgJoUiR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "  args = Namespace(\n",
        "      text_csv=\"nlptc/data/news.csv\",\n",
        "      train_csv=\"nlptc/data/train.csv\",\n",
        "      val_csv=\"nlptc/data/val.csv\",\n",
        "      test_csv=\"nlptc/data/test.csv\",\n",
        "      vectorizer_file=\"vectorizer.json\",\n",
        "      model_state_file=\"model.pth\",\n",
        "      save_dir=\"model_storage/Clf\",\n",
        "      glove_filepath='D:\\\\Projects\\\\Text Analytics\\\\Glove\\\\glove.6B.100d.txt',\n",
        "      hidden_dim=100,\n",
        "      num_channels=100,\n",
        "      seed=1337,\n",
        "      learning_rate=0.001,\n",
        "      dropout_p=0.1,\n",
        "      batch_size=64,\n",
        "      num_epochs=20,\n",
        "      early_stopping_criteria=5,\n",
        "      cuda=True,\n",
        "      catch_keyboard_interrupt=True,\n",
        "      reload_from_files=False,\n",
        "      expand_filepaths_to_save_dir=True,\n",
        "      token_type = 'w',\n",
        "      max_text_length = 256,\n",
        "      pretrained_embeddings= 'Glove',\n",
        "      embedding_size=100,\n",
        "      build_simple_char_cnn = False,\n",
        "      build_simple_word_cnn = True,\n",
        "      build_convrec_bilstm = False,\n",
        "      build_vdcnn = False,\n",
        "\n",
        "  )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c9vnHN-xoqL9",
        "colab_type": "code",
        "outputId": "e34edb5e-694f-4144-c3b4-0dc4978af8e6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "from nlptc.classes import *\n",
        "from nlptc.functions import *\n",
        "\n",
        "setup_environment(args)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Expanded filepaths: \n",
            "\tmodel_storage/Clf/vectorizer.json\n",
            "\tmodel_storage/Clf/model.pth\n",
            "Using CUDA: True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i3LQT9-ct_qA",
        "colab_type": "text"
      },
      "source": [
        "# Read Data file and split into Train, Validation and Test\n",
        "Text data file should have columns named as 'text' and 'category'. If the names are different, they should be renamed before processing further"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qdqEPUDYpVnU",
        "colab_type": "code",
        "outputId": "6e4cee03-2326-4158-aee6-37dbdb20ff8c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "dataframe_data = pd.read_csv(args.text_csv)\n",
        "        \n",
        "max_text_length = 256,\n",
        "args.token_type = 'w'\n",
        "#text_df = pd.read_csv(args.text_csv)\n",
        "text_df_orig = pd.read_csv(args.text_csv)\n",
        "print(text_df_orig.columns)\n",
        "\n",
        "text_df_orig.rename(columns={'title':'text'},inplace=True)\n",
        "text_df = text_df_orig[['text','category']] \n",
        "print(text_df.columns)\n",
        "\n",
        "dataset = NLPDatasets(text_df,args)\n",
        "train_df, val_df, test_df = dataset.get_splits()\n",
        "\n",
        "train_df.to_csv(args.train_csv, index=False)\n",
        "val_df.to_csv(args.val_csv, index=False)\n",
        "test_df.to_csv(args.test_csv, index=False)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Index(['title', 'category'], dtype='object')\n",
            "Index(['text', 'category'], dtype='object')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7lUgn56QpqL0",
        "colab_type": "code",
        "outputId": "7d61459f-6aca-4319-dc45-646b7f340560",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        }
      },
      "source": [
        "#dataframe_data = pd.read_csv('nlptc/data/train.csv')\n",
        "\n",
        "#encoder = preprocessing.LabelEncoder()\n",
        "#dataframe_data['sentiment'] = encoder.fit_transform(dataframe_data['sentiment'])\n",
        "\n",
        "#dataframe_train, dataframe_val = train_test_split(dataframe_data)\n",
        "#dataframe_train.to_csv(\"file_train.csv\", index=False)\n",
        "#dataframe_val.to_csv(\"file_val.csv\", index=False)\n",
        "\n",
        "train_df.head()\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>category</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>83622</th>\n",
              "      <td>Iran Says Preliminary Nuclear Deal Reached wit...</td>\n",
              "      <td>World</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>71641</th>\n",
              "      <td>Powell, Japan #39;s Machimura Discuss Iraq, Af...</td>\n",
              "      <td>World</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34791</th>\n",
              "      <td>China grabs software research deals despite risks</td>\n",
              "      <td>Sci/Tech</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9430</th>\n",
              "      <td>Williams-Sonoma Profit Up; Keeps Forecast (Reu...</td>\n",
              "      <td>Business</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>116739</th>\n",
              "      <td>HIH inquiry claims its biggest scalp</td>\n",
              "      <td>Business</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                     text  category\n",
              "83622   Iran Says Preliminary Nuclear Deal Reached wit...     World\n",
              "71641   Powell, Japan #39;s Machimura Discuss Iraq, Af...     World\n",
              "34791   China grabs software research deals despite risks  Sci/Tech\n",
              "9430    Williams-Sonoma Profit Up; Keeps Forecast (Reu...  Business\n",
              "116739               HIH inquiry claims its biggest scalp  Business"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fLb8wOozuR8z",
        "colab_type": "text"
      },
      "source": [
        "# Define TorchText Fields Variables and map them to Data file Columns\n",
        "TEXT variable maps to the text we will process. LABEL variable maps to Category associated with the TEXT.\n",
        "\n",
        "TEXT and LABEL are of type FIELD which is part of TorchText package. FIELD comes with many built in functions that help in simplifying proprocessing. For example we can pass tokenizer as the argument to TEXT. Using this, TorchText does automatic tokenization while parsing the Text File Columns\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P7hWe9xAqKPl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "nlp = spacy.load('en_core_web_sm')\n",
        "\n",
        "def tokenizer(sentence):\n",
        "    tokens = [w.text.lower() for w in nlp(clean_text(sentence))]\n",
        "    return tokens"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sKij3AjQp35E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Field_TEXT = data.Field(tokenize=tokenizer, sequential=True, \n",
        "                        use_vocab=True,batch_first=True,fix_length=args.max_text_length)\n",
        "Field_LABEL = data.LabelField(sequential=False)\n",
        "mapping_with_file_columns = [('text', Field_TEXT), ('category', Field_LABEL)]\n",
        "Dataset_train, Dataset_val = data.TabularDataset.splits(\n",
        "    path='',\n",
        "    train=args.train_csv,\n",
        "    validation=args.val_csv,\n",
        "    format='csv',\n",
        "    fields=mapping_with_file_columns,\n",
        "    skip_header=True\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YNUv-rrTxAww",
        "colab_type": "text"
      },
      "source": [
        "# Create TorchText Dataset wrappers around Train and Validation Data files\n",
        "TorchText Dataset is a wrapper around a normal data file. It comes with many build in functions that help simplify processing. Dataset wrapper needs the mapping between TorchText Fields and data file columns (as defined in the previous step) "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A5z9ujUHp5cd",
        "colab_type": "code",
        "outputId": "19f263ac-14ec-4cd9-810d-83f0b6137556",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        " Dataset_train, Dataset_val, Dataset_test = data.TabularDataset.splits(\n",
        "                                         path = '',\n",
        "                                         train = args.train_csv,\n",
        "                                         validation = args.val_csv,\n",
        "                                         test = args.test_csv,\n",
        "                                           format = 'csv',\n",
        "                                         fields = mapping_with_file_columns,\n",
        "                                         skip_header = True\n",
        "     )\n",
        "print(vars(Dataset_train[0]))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'text': ['iran', 'says', 'preliminary', 'nuclear', 'deal', 'reached', 'with', 'eu'], 'category': 'World'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8L2qMocP07Cm",
        "colab_type": "text"
      },
      "source": [
        "# Build Vocabulary and Word Vectors using the Datasets Created\n",
        "\n",
        "Volcabulary is list of unique Tokens in the text data. We will map each of the unique tokens to Word Vectors (or embeddings) using Glove Database"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QsEcoWUkp_Fl",
        "colab_type": "code",
        "outputId": "e82c1da3-4186-4564-bf92-6943f40df9ff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        " %%time\n",
        "MAX_VOCAB_SIZE = 25000\n",
        "#vec = vocab.Vectors('glove.6B.100d.txt', 'D:/qBots/nlptc/glove_embedding/')\n",
        "Field_TEXT.build_vocab(Dataset_train,Dataset_val,\n",
        "                  max_size = MAX_VOCAB_SIZE, \n",
        "                  vectors = \"glove.6B.100d\", \n",
        "##                vectors = vec,\n",
        "                  unk_init = torch.Tensor.normal_)\n",
        "Field_LABEL.build_vocab(Dataset_train)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 891 ms, sys: 130 ms, total: 1.02 s\n",
            "Wall time: 1.02 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZRIuJlJ4qJIE",
        "colab_type": "code",
        "outputId": "38fd1929-5eba-4789-b337-2cb5fad0f855",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "Field_TEXT.vocab.vectors.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([25002, 100])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c03yZbbI1vIU",
        "colab_type": "code",
        "outputId": "fca43276-9c85-4edf-b237-86775a576dd0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 243
        }
      },
      "source": [
        "Field_TEXT.vocab.vectors[Field_TEXT.vocab.stoi['testing']]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 0.1258,  0.2037, -0.1123,  0.3045, -0.9769, -0.5542,  0.4286,  0.7928,\n",
              "        -0.7157,  0.7587, -0.1077, -0.3529,  0.0333, -0.0764,  0.3469,  0.2451,\n",
              "         0.5385,  0.7100,  0.0522, -0.1323, -0.4734, -0.1800,  0.1982, -0.0651,\n",
              "        -0.4349,  0.4343, -0.0951, -0.3966, -0.4798,  0.4940, -0.3679,  0.2031,\n",
              "        -0.3497,  0.2970,  1.0122,  0.0933, -0.3492, -0.4592, -0.8168,  0.0374,\n",
              "        -0.8714, -0.1617, -0.0595, -0.4740, -0.3519,  0.2339,  0.4807, -0.6236,\n",
              "        -0.3462, -0.7426,  0.8620,  0.0581, -0.8875,  0.8843,  0.0444, -1.3311,\n",
              "        -0.7529,  0.0039,  1.9239, -0.0039,  0.2040,  0.3463,  0.9224,  0.5198,\n",
              "         0.4460,  0.6641, -0.2858, -0.2286,  0.1590,  0.1543, -0.0106,  0.5443,\n",
              "        -0.1647,  0.2509, -0.1672,  0.4843,  0.4626, -0.4024, -1.2572, -0.2214,\n",
              "         0.6287, -0.2696, -0.5828,  0.2838, -1.7209,  0.6726,  0.8789,  0.3482,\n",
              "        -0.9895,  0.4533, -0.5951,  0.0075,  0.0057,  0.5793,  0.6368,  0.5939,\n",
              "        -0.1434, -0.2136,  0.4768,  0.3917])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rqp1kuqL11Y8",
        "colab_type": "code",
        "outputId": "a455a852-0a87-4100-8bd5-7d89eabed2e4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "print(Field_LABEL.vocab.stoi)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "defaultdict(<function _default_unk_index at 0x7fb95ed2ca60>, {'Sci/Tech': 0, 'World': 1, 'Business': 2, 'Sports': 3})\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j6OesrOzcgSH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "embeddings = Field_TEXT.vocab.vectors.numpy()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hCbQTOvpv9B-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F2dwz4TJ19yg",
        "colab_type": "text"
      },
      "source": [
        "# Create the Torchtext Batches as wrapper around Dataset_train and Dataset_val for iterating over during Training/Validation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b6eIY6Q4qO1W",
        "colab_type": "code",
        "outputId": "94085232-6fda-41df-ab4a-2fd3085aa8c1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "BATCH_SIZE = 3\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "Batches_train, Batches_val, Batches_test = data.BucketIterator.splits(\n",
        "    (Dataset_train, Dataset_val,Dataset_test), \n",
        "    batch_size = args.batch_size,\n",
        "    sort_key=lambda x: len(x.text), \n",
        "    sort_within_batch=True, \n",
        "    device = device)\n",
        "\n",
        "print(\"***** Number of Train and Validation batches are :\",len(Batches_train), len(Batches_val))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "***** Number of Train and Validation batches are : 1055 352\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KkJsUN50qS16",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch = next(iter(Batches_train))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xJzEsYpA-VZd",
        "colab_type": "code",
        "outputId": "ee08e6bd-ffb7-40ff-f72c-de5f8c2bc04d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "batch.category.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([64])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "49lYv3H9cIcz",
        "colab_type": "code",
        "outputId": "e77c9333-75ab-4799-885e-6ef54ee87394",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "batch.text.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([64, 256])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e5-xAc27bz20",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def idxtosent(batch, idx):\n",
        "    return ' '.join([Field_TEXT.vocab.itos[i] for i in batch.text[idx,:].cpu().data.numpy()])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a_U9Xr0mb0yx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in range(2):\n",
        "  print(idxtosent(batch,i))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RRBNs5fVcbzT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class BatchGenerator:\n",
        "    def __init__(self, dl, x_field, y_field):\n",
        "        self.dl, self.x_field, self.y_field = dl, x_field, y_field\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.dl)\n",
        "    \n",
        "    def __iter__(self):\n",
        "        for batch in self.dl:\n",
        "            X = getattr(batch, self.x_field)\n",
        "            y = getattr(batch, self.y_field)\n",
        "            yield (X,y)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aXauuKqj3wgt",
        "colab_type": "text"
      },
      "source": [
        "# Define a Simpe Neural Network Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ypNBz4FprsWz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "class WordCNN_Simple(nn.Module):\n",
        "    def __init__(self, embedding_size, num_embeddings, num_channels,\n",
        "                 hidden_dim, num_classes, dropout_p,\n",
        "                 pretrained_embeddings=None, padding_idx=0):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            embedding_size (int): size of the embedding vectors\n",
        "            num_embeddings (int): number of embedding vectors\n",
        "            filter_width (int): width of the convolutional kernels\n",
        "            num_channels (int): number of convolutional kernels per layer\n",
        "            hidden_dim (int): the size of the hidden dimension\n",
        "            num_classes (int): the number of classes in classification\n",
        "            dropout_p (float): a dropout parameter\n",
        "            pretrained_embeddings (numpy.array): previously trained word embeddings\n",
        "                default is None. If provided,\n",
        "            padding_idx (int): an index representing a null position\n",
        "        \"\"\"\n",
        "        super(WordCNN_Simple, self).__init__()\n",
        "\n",
        "        if pretrained_embeddings is None:\n",
        "\n",
        "            self.emb = nn.Embedding(embedding_dim=embedding_size,\n",
        "                                    num_embeddings=num_embeddings,\n",
        "                                    padding_idx=padding_idx)\n",
        "        else:\n",
        "            pretrained_embeddings = torch.from_numpy(pretrained_embeddings).float()\n",
        "            self.emb = nn.Embedding(embedding_dim=embedding_size,\n",
        "                                    num_embeddings=num_embeddings,\n",
        "                                    padding_idx=padding_idx,\n",
        "                                    _weight=pretrained_embeddings)\n",
        "\n",
        "        self.convnet = nn.Sequential(\n",
        "            nn.Conv1d(in_channels=embedding_size,\n",
        "                      out_channels=num_channels, kernel_size=3),\n",
        "            nn.ELU(),\n",
        "            nn.Conv1d(in_channels=num_channels, out_channels=num_channels,\n",
        "                      kernel_size=3, stride=2),\n",
        "            nn.ELU(),\n",
        "            nn.Conv1d(in_channels=num_channels, out_channels=num_channels,\n",
        "                      kernel_size=3, stride=2),\n",
        "            nn.ELU(),\n",
        "            nn.Conv1d(in_channels=num_channels, out_channels=num_channels,\n",
        "                      kernel_size=3),\n",
        "            nn.ELU()\n",
        "        )\n",
        "\n",
        "        self._dropout_p = dropout_p\n",
        "        self.fc1 = nn.Linear(num_channels, hidden_dim)\n",
        "        self.fc2 = nn.Linear(hidden_dim, num_classes)\n",
        "\n",
        "    def forward(self, x_in, apply_softmax=False):\n",
        "        \"\"\"The forward pass of the classifier\n",
        "\n",
        "        Args:\n",
        "            x_in (torch.Tensor): an input data tensor.\n",
        "                x_in.shape should be (batch, dataset._max_seq_length)\n",
        "            apply_softmax (bool): a flag for the softmax activation\n",
        "                should be false if used with the Cross Entropy losses\n",
        "        Returns:\n",
        "            the resulting tensor. tensor.shape should be (batch, num_classes)\n",
        "        \"\"\"\n",
        "\n",
        "        # embed and permute so features are channels\n",
        "        x_embedded = self.emb(x_in).permute(0, 2, 1)\n",
        "\n",
        "        features = self.convnet(x_embedded)\n",
        "\n",
        "        # average and remove the extra dimension\n",
        "        remaining_size = features.size(dim=2)\n",
        "        features = F.avg_pool1d(features, remaining_size).squeeze(dim=2)\n",
        "        features = F.dropout(features, p=self._dropout_p)\n",
        "\n",
        "        # mlp classifier\n",
        "        intermediate_vector = F.relu(F.dropout(self.fc1(features), p=self._dropout_p))\n",
        "        prediction_vector = self.fc2(intermediate_vector)\n",
        "\n",
        "        if apply_softmax:\n",
        "            prediction_vector = F.softmax(prediction_vector, dim=1)\n",
        "\n",
        "        return prediction_vector"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pavGzAhmueTJ",
        "colab_type": "code",
        "outputId": "bf9214c1-63aa-4e0d-f423-7897579965bb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "embeddings = Field_TEXT.vocab.vectors.numpy()\n",
        "type(embeddings)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "numpy.ndarray"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3k7DiAfEvDPX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "classifier = WordCNN_Simple(embedding_size=args.embedding_size,\n",
        "                                    num_embeddings=len(Field_TEXT.vocab),\n",
        "                                    num_channels=args.num_channels,\n",
        "                                    hidden_dim=args.hidden_dim,\n",
        "                                    num_classes=len(Field_LABEL.vocab),\n",
        "                                    dropout_p=args.dropout_p,\n",
        "                                    pretrained_embeddings=embeddings,\n",
        "                                    padding_idx=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LRb3qOKewXfn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "classifier = classifier.to(device)\n",
        "#dataset.class_weights = dataset.class_weights.to(device)\n",
        "#loss_func = nn.CrossEntropyLoss(dataset.class_weights)\n",
        "loss_func = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(classifier.parameters(), lr=args.learning_rate)\n",
        "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer=optimizer,\n",
        "                                                  mode='min', factor=0.5,\n",
        "                                                  patience=1)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K-p_eL5R3ZKw",
        "colab_type": "code",
        "outputId": "c5325ab6-bcbe-4f45-e4ac-54646cc32981",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "text_df.rename(columns={'title':'text'},inplace=True)\n",
        "text_df.columns"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['text', 'category'], dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HkXGOJYJ2Ld-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vectorizer = Vectorizer(text_df)\n",
        "dataset._vectorizer = vectorizer\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZgluFDpo4XC3",
        "colab_type": "code",
        "outputId": "06b31825-fbc0-4dc2-cbfb-bae8f5135700",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "classifier = classifier.to(args.device)\n",
        "#dataset.class_weights = dataset.class_weights.to(args.device)\n",
        "#loss_func = nn.CrossEntropyLoss(dataset.class_weights)\n",
        "loss_func = nn.CrossEntropyLoss()\n",
        "\n",
        "optimizer = optim.Adam(classifier.parameters(), lr=args.learning_rate)\n",
        "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer=optimizer,\n",
        "                                                  mode='min', factor=0.5,\n",
        "                                                  patience=1)\n",
        "print(\"------- # of Parameters ---->: \", sum(p.numel() for p in classifier.parameters() if p.requires_grad))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "------- # of Parameters ---->:  2631104\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q5dcWDWz4pM-",
        "colab_type": "code",
        "outputId": "09f1a895-8e45-4c2e-efcd-6c9925eb5719",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "dataset.text_df.rename(columns={'title':'text'},inplace=True)\n",
        "dataset.text_df.columns"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['text', 'category'], dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6rNluqCHqhSr",
        "colab_type": "code",
        "outputId": "bca5b611-b558-4989-e761-3044c7968c5e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "print(f'The model has {count_parameters(classifier):,} trainable parameters')\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The model has 2,631,104 trainable parameters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jngUG9ue5PbX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_state = make_train_state(args)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4pYpaxHu7U6X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_batch_it = BatchGenerator(Batches_train, 'text', 'category')\n",
        "X,y = next(iter(train_batch_it))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t8i6F2Tn7jll",
        "colab_type": "code",
        "outputId": "872db0a0-0213-433a-a193-dd14517998c0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "print(X.shape)\n",
        "y_pred = classifier(X)\n",
        "print(y_pred.shape)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([64, 256])\n",
            "torch.Size([64, 4])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ca942BKH7y4e",
        "colab_type": "code",
        "outputId": "a30d3439-fe4c-458e-c9ac-349a364209eb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "y_pred.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([64, 4])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oZkpigi5WywV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def build_model(args,dataset,classifier,loss_func,optimizer,scheduler):\n",
        "\n",
        "    train_state = make_train_state(args)\n",
        "\n",
        "    try:\n",
        "        for epoch_index in range(args.num_epochs):\n",
        "            train_state['epoch_index'] = epoch_index\n",
        "            print(\"--------------------- @epoch \",epoch_index,\"---------------------\")\n",
        "\n",
        "            # Iterate over training dataset\n",
        "\n",
        "            # setup: batch generator, set loss and acc to 0, set train mode on\n",
        "\n",
        "            dataset.set_split('train')\n",
        "            batch_generator = generate_batches(dataset,\n",
        "                                               batch_size=args.batch_size,\n",
        "                                               device=args.device)\n",
        "            running_loss = 0.0\n",
        "            running_acc = 0.0\n",
        "            classifier.train()\n",
        "            batches = BatchGenerator(Batches_train, 'text', 'category')\n",
        "\n",
        "            for batch_index, batch_dict in enumerate(batches):\n",
        "              optimizer.zero_grad()\n",
        "              y_pred = classifier(batch_dict[0])\n",
        "              loss = loss_func(y_pred, batch_dict[1])\n",
        "              loss_t = loss.item()\n",
        "              running_loss += (loss_t - running_loss) / (batch_index + 1)\n",
        "              loss.backward()\n",
        "              optimizer.step()\n",
        "              acc_t = compute_accuracy(y_pred, batch_dict[1])\n",
        "              running_acc += (acc_t - running_acc) / (batch_index + 1)\n",
        "\n",
        "            train_state['train_loss'].append(running_loss)\n",
        "            train_state['train_acc'].append(running_acc)\n",
        "            print('  training loss/accuracy {:.5f} / {:.2f}'.format(running_loss, running_acc))\n",
        "\n",
        "            dataset.set_split('val')\n",
        "\n",
        "            batches = BatchGenerator(Batches_val, 'text', 'category')\n",
        "            running_loss = 0.\n",
        "            running_acc = 0.\n",
        "            classifier.eval()\n",
        "\n",
        "            for batch_index, batch_dict in enumerate(batches):\n",
        "              optimizer.zero_grad()\n",
        "              y_pred = classifier(batch_dict[0])\n",
        "              loss = loss_func(y_pred, batch_dict[1])\n",
        "              loss_t = loss.item()\n",
        "              running_loss += (loss_t - running_loss) / (batch_index + 1)\n",
        "              loss.backward()\n",
        "              optimizer.step()\n",
        "              acc_t = compute_accuracy(y_pred, batch_dict[1])\n",
        "              running_acc += (acc_t - running_acc) / (batch_index + 1)\n",
        "\n",
        "            train_state['val_loss'].append(running_loss)\n",
        "            train_state['val_acc'].append(running_acc)\n",
        "            print('validation loss/accuracy {:.5f} / {:.2f}'.format(running_loss, running_acc))\n",
        "\n",
        "            train_state = update_train_state(args=args, model=classifier,\n",
        "                                             train_state=train_state)\n",
        "\n",
        "            scheduler.step(train_state['val_loss'][-1])\n",
        "\n",
        "            if train_state['stop_early']:\n",
        "                break\n",
        "\n",
        "    except KeyboardInterrupt:\n",
        "        print(\"Exiting loop\")\n",
        "\n",
        "    # compute the loss & accuracy on the test set using the best available model\n",
        "\n",
        "    classifier.load_state_dict(torch.load(train_state['model_filename']))\n",
        "    classifier = classifier.to(args.device)\n",
        "    loss_func = nn.CrossEntropyLoss()\n",
        "    dataset.set_split('test')\n",
        "    batches = BatchGenerator(Batches_test, 'text', 'category')\n",
        "    running_loss = 0.\n",
        "    running_acc = 0.\n",
        "    classifier.eval()\n",
        "\n",
        "    for batch_index, batch_dict in enumerate(batches):\n",
        "      optimizer.zero_grad()\n",
        "      y_pred = classifier(batch_dict[0])\n",
        "      loss = loss_func(y_pred, batch_dict[1])\n",
        "      loss_t = loss.item()\n",
        "      running_loss += (loss_t - running_loss) / (batch_index + 1)\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "      acc_t = compute_accuracy(y_pred, batch_dict[1])\n",
        "      running_acc += (acc_t - running_acc) / (batch_index + 1)\n",
        "\n",
        "    train_state['test_loss'] = running_loss\n",
        "    train_state['test_acc'] = running_acc\n",
        "\n",
        "    print(\"Test loss: {:.3f}\".format(running_loss))\n",
        "    print(\"Test Accuracy: {:.2f}\".format(running_acc))\n",
        "\n",
        "    return train_state\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5AB60HS5mzgD",
        "colab_type": "code",
        "outputId": "04089566-92d1-4d31-e3b1-01f7e798301b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "results = build_model(args,dataset,classifier,loss_func,optimizer,scheduler)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--------------------- @epoch  0 ---------------------\n",
            "  training loss/accuracy 1.30919 / 31.06\n",
            "validation loss/accuracy 0.89407 / 54.15\n",
            "--------------------- @epoch  1 ---------------------\n",
            "  training loss/accuracy 0.50743 / 82.18\n",
            "validation loss/accuracy 0.38762 / 86.94\n",
            "--------------------- @epoch  2 ---------------------\n",
            "  training loss/accuracy 0.35369 / 88.30\n",
            "validation loss/accuracy 0.31346 / 89.59\n",
            "--------------------- @epoch  3 ---------------------\n",
            "  training loss/accuracy 0.28862 / 90.58\n",
            "validation loss/accuracy 0.26521 / 91.26\n",
            "--------------------- @epoch  4 ---------------------\n",
            "  training loss/accuracy 0.24929 / 91.86\n",
            "validation loss/accuracy 0.23265 / 92.58\n",
            "--------------------- @epoch  5 ---------------------\n",
            "  training loss/accuracy 0.22109 / 92.85\n",
            "validation loss/accuracy 0.20563 / 93.24\n",
            "--------------------- @epoch  6 ---------------------\n",
            "  training loss/accuracy 0.19406 / 93.72\n",
            "validation loss/accuracy 0.18329 / 94.26\n",
            "--------------------- @epoch  7 ---------------------\n",
            "  training loss/accuracy 0.16789 / 94.60\n",
            "validation loss/accuracy 0.16313 / 94.82\n",
            "--------------------- @epoch  8 ---------------------\n",
            "  training loss/accuracy 0.14915 / 95.21\n",
            "validation loss/accuracy 0.14264 / 95.35\n",
            "--------------------- @epoch  9 ---------------------\n",
            "  training loss/accuracy 0.12754 / 95.91\n",
            "validation loss/accuracy 0.12574 / 95.93\n",
            "--------------------- @epoch  10 ---------------------\n",
            "  training loss/accuracy 0.11097 / 96.32\n",
            "validation loss/accuracy 0.11004 / 96.32\n",
            "--------------------- @epoch  11 ---------------------\n",
            "  training loss/accuracy 0.09642 / 96.75\n",
            "validation loss/accuracy 0.09200 / 96.78\n",
            "--------------------- @epoch  12 ---------------------\n",
            "  training loss/accuracy 0.08257 / 97.14\n",
            "validation loss/accuracy 0.08511 / 96.90\n",
            "--------------------- @epoch  13 ---------------------\n",
            "  training loss/accuracy 0.07361 / 97.46\n",
            "validation loss/accuracy 0.07224 / 97.19\n",
            "--------------------- @epoch  14 ---------------------\n",
            "  training loss/accuracy 0.06352 / 97.76\n",
            "validation loss/accuracy 0.06329 / 97.58\n",
            "--------------------- @epoch  15 ---------------------\n",
            "  training loss/accuracy 0.05547 / 97.98\n",
            "validation loss/accuracy 0.05483 / 97.89\n",
            "--------------------- @epoch  16 ---------------------\n",
            "  training loss/accuracy 0.04954 / 98.20\n",
            "validation loss/accuracy 0.05316 / 97.98\n",
            "--------------------- @epoch  17 ---------------------\n",
            "  training loss/accuracy 0.04513 / 98.25\n",
            "validation loss/accuracy 0.04453 / 98.24\n",
            "--------------------- @epoch  18 ---------------------\n",
            "  training loss/accuracy 0.04094 / 98.48\n",
            "validation loss/accuracy 0.04342 / 98.16\n",
            "--------------------- @epoch  19 ---------------------\n",
            "  training loss/accuracy 0.03747 / 98.62\n",
            "validation loss/accuracy 0.03966 / 98.33\n",
            "Test loss: 0.175\n",
            "Test Accuracy: 94.94\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qqiXMerb5S5e",
        "colab_type": "code",
        "outputId": "2aca55c1-ca71-45a4-ef17-706cd7e409c6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "print(results)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'stop_early': False, 'early_stopping_step': 0, 'early_stopping_best_val': 100000000.0, 'learning_rate': 0.001, 'epoch_index': 19, 'train_loss': [1.3091858076258294, 0.5074347156483979, 0.35368603939693766, 0.2886233720734219, 0.2492928947494214, 0.22108668155297276, 0.1940635639220761, 0.1678905941775483, 0.1491452649244555, 0.12753541925789616, 0.1109703586423567, 0.09641759916963455, 0.08256678381202052, 0.07361107674290504, 0.06352113793831386, 0.05546512596410703, 0.04954216448740234, 0.04512659004002246, 0.040942304286558436, 0.037469739202957285], 'train_acc': [31.062715424386024, 82.17982550624733, 88.29707022834991, 90.57922231796634, 91.8618052563551, 92.85060318828086, 93.72037914691938, 94.60092632485994, 95.21178909952613, 95.90868698836714, 96.32041684618682, 96.74547608789317, 97.13714454976306, 97.45704976303335, 97.75622037914701, 97.9828199052133, 98.19689788884097, 98.25385071090042, 98.47896919431274, 98.62491921585524], 'val_loss': [0.8940749955786901, 0.38762404668060235, 0.31346138520166306, 0.2652069858635182, 0.23265165295346044, 0.20563046180971228, 0.18329081135611475, 0.16313475944281725, 0.1426449796206062, 0.12573810036833907, 0.11004470552804625, 0.09200030689085409, 0.0851103411788989, 0.0722395612762987, 0.06328604697905993, 0.0548325610365365, 0.0531617980159353, 0.044527466560545896, 0.0434236308201712, 0.03965846183630431], 'val_acc': [54.152856691919176, 86.94069602272728, 89.58629261363639, 91.259765625, 92.58256392045455, 93.23952414772722, 94.26491477272727, 94.81977982954544, 95.35245028409086, 95.93394886363637, 96.32013494318184, 96.78276909722223, 96.89719460227269, 97.19016335227278, 97.58078835227279, 97.88707386363633, 97.98029119318178, 98.23774857954538, 98.15784801136364, 98.32652698863643], 'test_loss': 0.17536472233235822, 'test_acc': 94.93999999999984, 'model_filename': 'model_storage/Clf/model.pth'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jrz_wRzQ5S3A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}